{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3BQKLY2v8Dm",
        "outputId": "26a30865-8739-4c01-b4c9-d159d99c24a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: groq in /usr/local/lib/python3.12/dist-packages (0.32.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.1.1)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (0.3.78)\n",
            "Requirement already satisfied: langchain-groq in /usr/local/lib/python3.12/dist-packages (0.3.8)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.11.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.4.33)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (6.0.3)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (25.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2.5.0)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0müöÄ Starting Groq Agent with Current Models...\n",
            "üß™ Testing ALL Potential Groq Models...\n",
            "\n",
            "Testing: llama-3.1-8b-instant\n",
            "‚úÖ SUCCESS - llama-3.1-8b-instant\n",
            "   Response: Solar energy has several benefits....\n",
            "\n",
            "Testing: llama-3.2-1b-preview\n",
            "‚ùå FAILED - llama-3.2-1b-preview\n",
            "   Reason: Model decommissioned\n",
            "\n",
            "Testing: llama-3.2-3b-preview\n",
            "‚ùå FAILED - llama-3.2-3b-preview\n",
            "   Reason: Model decommissioned\n",
            "\n",
            "Testing: llama-3.2-90b-vision-preview\n",
            "‚ùå FAILED - llama-3.2-90b-vision-preview\n",
            "   Reason: Model decommissioned\n",
            "\n",
            "Testing: llama-3.2-11b-vision-preview\n",
            "‚ùå FAILED - llama-3.2-11b-vision-preview\n",
            "   Reason: Model decommissioned\n",
            "\n",
            "Testing: llama-3.2-90b-text-preview\n",
            "‚ùå FAILED - llama-3.2-90b-text-preview\n",
            "   Reason: Model decommissioned\n",
            "\n",
            "Testing: llama-3.2-1b-text-preview\n",
            "‚ùå FAILED - llama-3.2-1b-text-preview\n",
            "   Reason: Failed to get response: Error code: 404 - {'error': {'message': 'The model `llama-3.2-1b-text-previe...\n",
            "\n",
            "Testing: llama-3.2-3b-text-preview\n",
            "‚ùå FAILED - llama-3.2-3b-text-preview\n",
            "   Reason: Failed to get response: Error code: 404 - {'error': {'message': 'The model `llama-3.2-3b-text-previe...\n",
            "\n",
            "Testing: mixtral-8x7b-32768\n",
            "‚ùå FAILED - mixtral-8x7b-32768\n",
            "   Reason: Model decommissioned\n",
            "\n",
            "Testing: gemma2-9b-it\n",
            "‚ùå FAILED - gemma2-9b-it\n",
            "   Reason: Model decommissioned\n",
            "\n",
            "Testing: llama3-8b-8192\n",
            "‚ùå FAILED - llama3-8b-8192\n",
            "   Reason: Model decommissioned\n",
            "\n",
            "Testing: llama3-70b-8192\n",
            "‚ùå FAILED - llama3-70b-8192\n",
            "   Reason: Model decommissioned\n",
            "\n",
            "üéØ WORKING MODELS: ['llama-3.1-8b-instant']\n",
            "\n",
            "üéâ Found 1 working model(s): ['llama-3.1-8b-instant']\n",
            "\n",
            "======================================================================\n",
            "RUNNING MAIN DEMO WITH WORKING MODEL\n",
            "======================================================================\n",
            "ü§ñ Simple Groq Agent Demo\n",
            "Using model: llama-3.1-8b-instant\n",
            "\n",
            "============================================================\n",
            "1. Basic Structured Response:\n",
            "============================================================\n",
            "Prompt: Explain the benefits of renewable energy in 3 key points\n",
            "Response:\n",
            "{\n",
            "  \"summary\": \"Renewable energy offers numerous benefits for the environment and human societies.\",\n",
            "  \"key_points\": [\n",
            "    \"Reduces greenhouse gas emissions and mitigates climate change\",\n",
            "    \"Decreases dependence on fossil fuels, conserving natural resources\",\n",
            "    \"Creates jobs, stimulates local economies, and reduces air pollution\"\n",
            "  ],\n",
            "  \"action_items\": [],\n",
            "  \"sentiment\": \"positive\",\n",
            "  \"confidence_score\": 0.95\n",
            "}\n",
            "\n",
            "============================================================\n",
            "2. Custom Structured Response:\n",
            "============================================================\n",
            "Prompt: Create a product idea for a smart home device for elderly people\n",
            "Response:\n",
            "{\n",
            "  \"product_name\": \"CareMate\",\n",
            "  \"features\": [\n",
            "    \"Motion sensing to detect falls and emergencies\",\n",
            "    \"Voice assistant integration for hands-free communication\",\n",
            "    \"Medication reminders and scheduling\",\n",
            "    \"Temperature and lighting control\",\n",
            "    \"Fall detection alerts sent to caregivers\",\n",
            "    \"Integration with wearable devices for health monitoring\"\n",
            "  ],\n",
            "  \"target_audience\": \"Elderly individuals living alone or with caregivers\",\n",
            "  \"price_estimate\": 249.99,\n",
            "  \"development_timeline\": \"6-9 months\"\n",
            "}\n",
            "\n",
            "============================================================\n",
            "3. Analysis with Structured Output:\n",
            "============================================================\n",
            "Prompt: Perform a SWOT analysis for electric vehicles in 2024\n",
            "Response:\n",
            "{\n",
            "  \"topic\": \"Electric Vehicles in 2024\",\n",
            "  \"strengths\": [\n",
            "    \"Increasing government incentives and tax credits for EV purchases\",\n",
            "    \"Advancements in battery technology leading to improved range and efficiency\",\n",
            "    \"Growing demand for sustainable transportation and reduced carbon emissions\",\n",
            "    \"Established partnerships between automakers and charging infrastructure providers\",\n",
            "    \"Competitive pricing and models available in various segments\"\n",
            "  ],\n",
            "  \"weaknesses\": [\n",
            "    \"Limited charging infrastructure in rural areas and long road trips\",\n",
            "    \"Higher upfront costs compared to traditional internal combustion engine vehicles\",\n",
            "    \"Dependence on finite resources for battery production, such as lithium\",\n",
            "    \"Limited model options and brand choices in certain markets\",\n",
            "    \"Charging speed and convenience still a concern for some consumers\"\n",
            "  ],\n",
            "  \"opportunities\": [\n",
            "    \"Expanding into new markets and countries with growing demand for EVs\",\n",
            "    \"Developing more efficient and cost-effective battery production methods\",\n",
            "    \"Collaborating with governments and private companies to improve charging infrastructure\",\n",
            "    \"Increasing public awareness and education on the benefits of EVs\",\n",
            "    \"Potential for EVs to become a dominant force in the automotive industry\"\n",
            "  ],\n",
            "  \"threats\": [\n",
            "    \"Rising competition from emerging EV manufacturers and new market entrants\",\n",
            "    \"Regulatory challenges and changes in government policies and incentives\",\n",
            "    \"Uncertainty surrounding the global supply of critical materials for EV production\",\n",
            "    \"Potential for increased competition from hydrogen fuel cell vehicles\",\n",
            "    \"Cybersecurity risks and data protection concerns associated with connected vehicles\"\n",
            "  ],\n",
            "  \"overall_assessment\": \"Electric vehicles are poised for significant growth and adoption in 2024, driven by increasing demand for sustainable transportation, advancements in technology, and supportive government policies. However, challenges related to charging infrastructure, pricing, and resource availability still need to be addressed to fully realize the potential of EVs.\"\n",
            "}\n",
            "\n",
            "==================================================\n",
            "CONVERSATION HISTORY\n",
            "==================================================\n",
            "\n",
            "[1] USER (2025-10-16T16:19:35.289694):\n",
            "Explain the benefits of renewable energy in 3 key points\n",
            "\n",
            "[2] ASSISTANT (2025-10-16T16:19:35.289750):\n",
            "{\n",
            "  \"summary\": \"Renewable energy offers numerous benefits for the environment and human societies.\",\n",
            "  \"key_points\": [\n",
            "    \"Reduces greenhouse gas emissions and mitigates climate change\",\n",
            "    \"Decreases dependence on fossil fuels, conserving natural resources\",\n",
            "    \"Creates jobs, stimulates local economies, and reduces air pollution\"\n",
            "  ],\n",
            "  \"action_items\": [],\n",
            "  \"sentiment\": \"positive\",\n",
            "  \"confidence_score\": 0.95\n",
            "}\n",
            "\n",
            "[3] USER (2025-10-16T16:19:35.884257):\n",
            "Create a product idea for a smart home device for elderly people\n",
            "\n",
            "[4] ASSISTANT (2025-10-16T16:19:35.884333):\n",
            "{\n",
            "  \"product_name\": \"CareMate\",\n",
            "  \"features\": [\n",
            "    \"Motion sensing to detect falls and emergencies\",\n",
            "    \"Voice assistant integration for hands-free communication\",\n",
            "    \"Medication reminders and scheduling\",\n",
            "    \"Temperature and lighting control\",\n",
            "    \"Fall detection alerts sent to caregivers\",\n",
            "    \"Integration with wearable devices for health monitoring\"\n",
            "  ],\n",
            "  \"target_audience\": \"Elderly individuals living alone or with caregivers\",\n",
            "  \"price_estimate\": 249.99,\n",
            "  \"development_timeline\": \"6-9 months\"\n",
            "}\n",
            "\n",
            "[5] USER (2025-10-16T16:19:37.000055):\n",
            "Perform a SWOT analysis for electric vehicles in 2024\n",
            "\n",
            "[6] ASSISTANT (2025-10-16T16:19:37.000124):\n",
            "{\n",
            "  \"topic\": \"Electric Vehicles in 2024\",\n",
            "  \"strengths\": [\n",
            "    \"Increasing government incentives and tax credits for EV purchases\",\n",
            "    \"Advancements in battery technology leading to improved range and efficiency\",\n",
            "    \"Growing demand for sustainable transportation and reduced carbon emissions\",\n",
            "    \"Established partnerships between automakers and charging infrastructure providers\",\n",
            "    \"Competitive pricing and models available in various segments\"\n",
            "  ],\n",
            "  \"weaknesses\": [\n",
            "    \"Limited charging infrastructure in rural areas and long road trips\",\n",
            "    \"Higher upfront costs compared to traditional internal combustion engine vehicles\",\n",
            "    \"Dependence on finite resources for battery production, such as lithium\",\n",
            "    \"Limited model options and brand choices in certain markets\",\n",
            "    \"Charging speed and convenience still a concern for some consumers\"\n",
            "  ],\n",
            "  \"opportunities\": [\n",
            "    \"Expanding into new markets and countries with growing demand for EVs\",\n",
            "    \"Developing more efficient and cost-effective battery production methods\",\n",
            "    \"Collaborating with governments and private companies to improve charging infrastructure\",\n",
            "    \"Increasing public awareness and education on the benefits of EVs\",\n",
            "    \"Potential for EVs to become a dominant force in the automotive industry\"\n",
            "  ],\n",
            "  \"threats\": [\n",
            "    \"Rising competition from emerging EV manufacturers and new market entrants\",\n",
            "    \"Regulatory challenges and changes in government policies and incentives\",\n",
            "    \"Uncertainty surrounding the global supply of critical materials for EV production\",\n",
            "    \"Potential for increased competition from hydrogen fuel cell vehicles\",\n",
            "    \"Cybersecurity risks and data protection concerns associated with connected vehicles\"\n",
            "  ],\n",
            "  \"overall_assessment\": \"Electric vehicles are poised for significant growth and adoption in 2024, driven by increasing demand for sustainable transportation, advancements in technology, and supportive government policies. However, challenges related to charging infrastructure, pricing, and resource availability still need to be addressed to fully realize the potential of EVs.\"\n",
            "}\n",
            "==================================================\n",
            "\n",
            "============================================================\n",
            "ADVANCED AGENT WITH TOOLS\n",
            "============================================================\n",
            "\n",
            "üîß Testing Calculator Tool:\n",
            "Tool-based response:\n",
            "{\n",
            "  \"analysis\": \"The given problem is a basic arithmetic expression involving multiplication and addition. It requires the application of the order of operations (PEMDAS/BODMAS) where multiplication is performed before addition.\",\n",
            "  \"tool_used\": \"calculator\",\n",
            "  \"tool_result\": \"110\",\n",
            "  \"final_answer\": \"The result of 25 * 4 + 10 is 110.\"\n",
            "}\n",
            "\n",
            "‚è∞ Testing Time Tool:\n",
            "Tool-based response:\n",
            "{\n",
            "  \"analysis\": \"The current time was determined using the 'time' tool.\",\n",
            "  \"tool_used\": \"time\",\n",
            "  \"tool_result\": \"2025-10-16 16:19:37\",\n",
            "  \"final_answer\": \"The current time is 2025-10-16 16:19:37.\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install groq python-dotenv langchain-core langchain-groq\n",
        "\n",
        "# Import necessary libraries\n",
        "import os\n",
        "from groq import Groq\n",
        "from typing import Dict, List, Optional\n",
        "import json\n",
        "from datetime import datetime\n",
        "import requests\n",
        "\n",
        "# Set up Groq API (You'll need to get a free API key from https://console.groq.com/)\n",
        "os.environ[\"GROQ_API_KEY\"] = \"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\"  # Replace with your actual key\n",
        "\n",
        "# Initialize Groq client\n",
        "client = Groq(api_key=os.environ[\"GROQ_API_KEY\"])\n",
        "\n",
        "class SimpleAgent:\n",
        "    def __init__(self, model: str = \"llama-3.1-8b-instant\"):\n",
        "        self.client = Groq(api_key=os.environ[\"GROQ_API_KEY\"])\n",
        "        self.model = model\n",
        "        self.conversation_history = []\n",
        "\n",
        "    def add_to_history(self, role: str, content: str):\n",
        "        \"\"\"Add message to conversation history\"\"\"\n",
        "        self.conversation_history.append({\n",
        "            \"role\": role,\n",
        "            \"content\": content,\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        })\n",
        "\n",
        "    def get_available_models(self) -> List[str]:\n",
        "        \"\"\"Get list of CURRENTLY AVAILABLE Groq models\"\"\"\n",
        "        return [\n",
        "            \"llama-3.1-8b-instant\",  # This one works!\n",
        "            \"llama-3.2-1b-preview\",  # New smaller model\n",
        "            \"llama-3.2-3b-preview\",  # New medium model\n",
        "            \"llama-3.2-90b-vision-preview\",  # Large model with vision\n",
        "            \"llama-3.2-11b-vision-preview\",  # Medium with vision\n",
        "            \"llama-3.2-90b-text-preview\",  # Large text model\n",
        "            \"mixtral-8x7b-32768\"  # Some legacy might work\n",
        "        ]\n",
        "\n",
        "    def get_structured_response(self,\n",
        "                              prompt: str,\n",
        "                              response_format: Dict = None,\n",
        "                              max_tokens: int = 1024,\n",
        "                              temperature: float = 0.7) -> Dict:\n",
        "        \"\"\"\n",
        "        Get structured response from the agent\n",
        "        \"\"\"\n",
        "\n",
        "        # Default response format if none provided\n",
        "        if response_format is None:\n",
        "            response_format = {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"summary\": {\"type\": \"string\"},\n",
        "                    \"key_points\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
        "                    \"action_items\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
        "                    \"sentiment\": {\"type\": \"string\", \"enum\": [\"positive\", \"negative\", \"neutral\"]},\n",
        "                    \"confidence_score\": {\"type\": \"number\", \"minimum\": 0, \"maximum\": 1}\n",
        "                },\n",
        "                \"required\": [\"summary\", \"key_points\", \"action_items\", \"sentiment\", \"confidence_score\"]\n",
        "            }\n",
        "\n",
        "        # System prompt for structured responses\n",
        "        system_prompt = f\"\"\"\n",
        "        You are a helpful AI assistant that provides structured responses.\n",
        "        Always respond in valid JSON format matching this schema:\n",
        "        {json.dumps(response_format, indent=2)}\n",
        "\n",
        "        Ensure your response is parseable JSON and follows the schema exactly.\n",
        "        Return ONLY the JSON object, no additional text.\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            # Create chat completion\n",
        "            completion = self.client.chat.completions.create(\n",
        "                model=self.model,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": system_prompt},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                temperature=temperature,\n",
        "                max_tokens=max_tokens,\n",
        "                top_p=1,\n",
        "                stream=False,\n",
        "                response_format={\"type\": \"json_object\"}\n",
        "            )\n",
        "\n",
        "            response_content = completion.choices[0].message.content\n",
        "\n",
        "            # Parse JSON response\n",
        "            structured_response = json.loads(response_content)\n",
        "\n",
        "            # Add to history\n",
        "            self.add_to_history(\"user\", prompt)\n",
        "            self.add_to_history(\"assistant\", json.dumps(structured_response, indent=2))\n",
        "\n",
        "            return structured_response\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Failed to get response: {str(e)}\"\n",
        "            self.add_to_history(\"system\", error_msg)\n",
        "            return {\"error\": error_msg}\n",
        "\n",
        "    def print_conversation_history(self):\n",
        "        \"\"\"Print the conversation history\"\"\"\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"CONVERSATION HISTORY\")\n",
        "        print(\"=\"*50)\n",
        "        for i, message in enumerate(self.conversation_history):\n",
        "            print(f\"\\n[{i+1}] {message['role'].upper()} ({message['timestamp']}):\")\n",
        "            if message['role'] == 'assistant':\n",
        "                try:\n",
        "                    # Pretty print JSON responses\n",
        "                    parsed = json.loads(message['content'])\n",
        "                    print(json.dumps(parsed, indent=2))\n",
        "                except:\n",
        "                    print(message['content'])\n",
        "            else:\n",
        "                print(message['content'])\n",
        "        print(\"=\"*50)\n",
        "\n",
        "# Test ALL current models\n",
        "def test_all_models():\n",
        "    \"\"\"Test all potential Groq models\"\"\"\n",
        "    agent = SimpleAgent()\n",
        "\n",
        "    # Extended list of possible models\n",
        "    all_possible_models = [\n",
        "        \"llama-3.1-8b-instant\",\n",
        "        \"llama-3.2-1b-preview\",\n",
        "        \"llama-3.2-3b-preview\",\n",
        "        \"llama-3.2-90b-vision-preview\",\n",
        "        \"llama-3.2-11b-vision-preview\",\n",
        "        \"llama-3.2-90b-text-preview\",\n",
        "        \"llama-3.2-1b-text-preview\",\n",
        "        \"llama-3.2-3b-text-preview\",\n",
        "        \"mixtral-8x7b-32768\",\n",
        "        \"gemma2-9b-it\",\n",
        "        \"llama3-8b-8192\",\n",
        "        \"llama3-70b-8192\"\n",
        "    ]\n",
        "\n",
        "    print(\"üß™ Testing ALL Potential Groq Models...\")\n",
        "    working_models = []\n",
        "\n",
        "    test_prompt = \"What are 2 benefits of solar energy? Return as JSON.\"\n",
        "\n",
        "    for model in all_possible_models:\n",
        "        print(f\"\\nTesting: {model}\")\n",
        "        try:\n",
        "            agent.model = model\n",
        "            response = agent.get_structured_response(test_prompt)\n",
        "\n",
        "            if \"error\" not in response:\n",
        "                print(f\"‚úÖ SUCCESS - {model}\")\n",
        "                working_models.append(model)\n",
        "                # Show a snippet of the response\n",
        "                summary = response.get('summary', 'N/A')[:100] + \"...\" if response.get('summary') else 'N/A'\n",
        "                print(f\"   Response: {summary}\")\n",
        "            else:\n",
        "                print(f\"‚ùå FAILED - {model}\")\n",
        "                # Show error message\n",
        "                error_msg = response['error']\n",
        "                if \"decommissioned\" in error_msg:\n",
        "                    print(\"   Reason: Model decommissioned\")\n",
        "                elif \"not found\" in error_msg:\n",
        "                    print(\"   Reason: Model not found\")\n",
        "                else:\n",
        "                    print(f\"   Reason: {error_msg[:100]}...\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå ERROR - {model}: {str(e)[:100]}...\")\n",
        "\n",
        "    print(f\"\\nüéØ WORKING MODELS: {working_models}\")\n",
        "    return working_models\n",
        "\n",
        "# Example usage with guaranteed working model\n",
        "def demo_structured_agent():\n",
        "    # Use the confirmed working model\n",
        "    agent = SimpleAgent(model=\"llama-3.1-8b-instant\")\n",
        "\n",
        "    print(\"ü§ñ Simple Groq Agent Demo\")\n",
        "    print(f\"Using model: {agent.model}\")\n",
        "\n",
        "    # Example 1: Basic structured response\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"1. Basic Structured Response:\")\n",
        "    print(\"=\"*60)\n",
        "    prompt1 = \"Explain the benefits of renewable energy in 3 key points\"\n",
        "    response1 = agent.get_structured_response(prompt1)\n",
        "    print(\"Prompt:\", prompt1)\n",
        "    print(\"Response:\")\n",
        "    print(json.dumps(response1, indent=2))\n",
        "\n",
        "    # Example 2: Custom response format\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"2. Custom Structured Response:\")\n",
        "    print(\"=\"*60)\n",
        "    custom_format = {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"product_name\": {\"type\": \"string\"},\n",
        "            \"features\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
        "            \"target_audience\": {\"type\": \"string\"},\n",
        "            \"price_estimate\": {\"type\": \"number\"},\n",
        "            \"development_timeline\": {\"type\": \"string\"}\n",
        "        },\n",
        "        \"required\": [\"product_name\", \"features\", \"target_audience\", \"price_estimate\", \"development_timeline\"]\n",
        "    }\n",
        "\n",
        "    prompt2 = \"Create a product idea for a smart home device for elderly people\"\n",
        "    response2 = agent.get_structured_response(prompt2, response_format=custom_format)\n",
        "    print(\"Prompt:\", prompt2)\n",
        "    print(\"Response:\")\n",
        "    print(json.dumps(response2, indent=2))\n",
        "\n",
        "    # Example 3: Analysis with structured output\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"3. Analysis with Structured Output:\")\n",
        "    print(\"=\"*60)\n",
        "    analysis_format = {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"topic\": {\"type\": \"string\"},\n",
        "            \"strengths\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
        "            \"weaknesses\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
        "            \"opportunities\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
        "            \"threats\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
        "            \"overall_assessment\": {\"type\": \"string\"}\n",
        "        },\n",
        "        \"required\": [\"topic\", \"strengths\", \"weaknesses\", \"opportunities\", \"threats\", \"overall_assessment\"]\n",
        "    }\n",
        "\n",
        "    prompt3 = \"Perform a SWOT analysis for electric vehicles in 2024\"\n",
        "    response3 = agent.get_structured_response(prompt3, response_format=analysis_format)\n",
        "    print(\"Prompt:\", prompt3)\n",
        "    print(\"Response:\")\n",
        "    print(json.dumps(response3, indent=2))\n",
        "\n",
        "    # Show conversation history\n",
        "    agent.print_conversation_history()\n",
        "\n",
        "# Advanced agent with tools\n",
        "class AdvancedAgent(SimpleAgent):\n",
        "    def __init__(self, model: str = \"llama-3.1-8b-instant\"):\n",
        "        super().__init__(model)\n",
        "        self.tools = {\n",
        "            \"calculator\": self.calculate,\n",
        "            \"time\": self.get_current_time,\n",
        "            \"text_analyzer\": self.analyze_text\n",
        "        }\n",
        "\n",
        "    def calculate(self, expression: str) -> float:\n",
        "        \"\"\"Simple calculator tool\"\"\"\n",
        "        try:\n",
        "            # Safety check - only allow basic math operations\n",
        "            allowed_chars = set('0123456789+-*/.() ')\n",
        "            if all(c in allowed_chars for c in expression):\n",
        "                return eval(expression)\n",
        "            else:\n",
        "                return \"Error: Invalid characters in expression\"\n",
        "        except:\n",
        "            return \"Error: Could not evaluate expression\"\n",
        "\n",
        "    def get_current_time(self) -> str:\n",
        "        \"\"\"Get current time tool\"\"\"\n",
        "        return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "    def analyze_text(self, text: str) -> Dict:\n",
        "        \"\"\"Simple text analysis tool\"\"\"\n",
        "        words = len(text.split())\n",
        "        chars = len(text)\n",
        "        return {\n",
        "            \"word_count\": words,\n",
        "            \"character_count\": chars,\n",
        "            \"reading_time_minutes\": round(words / 200, 2)\n",
        "        }\n",
        "\n",
        "    def process_with_tools(self, prompt: str) -> Dict:\n",
        "        \"\"\"Process prompt with available tools\"\"\"\n",
        "\n",
        "        tool_result = \"No tool used\"\n",
        "        tool_used = \"none\"\n",
        "\n",
        "        # Simple tool detection\n",
        "        if any(word in prompt.lower() for word in ['calculate', 'math', '+', '-', '*', '/']):\n",
        "            tool_used = \"calculator\"\n",
        "            # Extract simple math expressions\n",
        "            import re\n",
        "            numbers = re.findall(r'\\d+\\.?\\d*', prompt)\n",
        "            if numbers and len(numbers) >= 2:\n",
        "                tool_result = str(self.calculate('+'.join(numbers)))\n",
        "            else:\n",
        "                tool_result = \"Could not extract calculation\"\n",
        "\n",
        "        elif \"time\" in prompt.lower():\n",
        "            tool_used = \"time\"\n",
        "            tool_result = self.get_current_time()\n",
        "\n",
        "        elif \"analyze\" in prompt.lower() and \"text\" in prompt.lower():\n",
        "            tool_used = \"text_analyzer\"\n",
        "            tool_result = str(self.analyze_text(prompt))\n",
        "\n",
        "        # Get final response\n",
        "        tool_format = {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"analysis\": {\"type\": \"string\"},\n",
        "                \"tool_used\": {\"type\": \"string\"},\n",
        "                \"tool_result\": {\"type\": \"string\"},\n",
        "                \"final_answer\": {\"type\": \"string\"}\n",
        "            },\n",
        "            \"required\": [\"analysis\", \"tool_used\", \"tool_result\", \"final_answer\"]\n",
        "        }\n",
        "\n",
        "        final_prompt = f\"\"\"\n",
        "        Original prompt: {prompt}\n",
        "        Tool used: {tool_used}\n",
        "        Tool result: {tool_result}\n",
        "\n",
        "        Provide a comprehensive answer using the tool result if applicable.\n",
        "        \"\"\"\n",
        "\n",
        "        return self.get_structured_response(final_prompt, response_format=tool_format)\n",
        "\n",
        "# Run the complete demo\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"üöÄ Starting Groq Agent with Current Models...\")\n",
        "\n",
        "    # First, test all models to find working ones\n",
        "    working_models = test_all_models()\n",
        "\n",
        "    if working_models:\n",
        "        print(f\"\\nüéâ Found {len(working_models)} working model(s): {working_models}\")\n",
        "\n",
        "        # Run main demo with first working model\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"RUNNING MAIN DEMO WITH WORKING MODEL\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        demo_structured_agent()\n",
        "\n",
        "        # Test advanced agent\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"ADVANCED AGENT WITH TOOLS\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        advanced_agent = AdvancedAgent(model=working_models[0])\n",
        "\n",
        "        # Test calculator tool\n",
        "        print(\"\\nüîß Testing Calculator Tool:\")\n",
        "        tool_response1 = advanced_agent.process_with_tools(\"Calculate 25 * 4 + 10\")\n",
        "        print(\"Tool-based response:\")\n",
        "        print(json.dumps(tool_response1, indent=2))\n",
        "\n",
        "        # Test time tool\n",
        "        print(\"\\n‚è∞ Testing Time Tool:\")\n",
        "        tool_response2 = advanced_agent.process_with_tools(\"What's the current time?\")\n",
        "        print(\"Tool-based response:\")\n",
        "        print(json.dumps(tool_response2, indent=2))\n",
        "\n",
        "    else:\n",
        "        print(\"\\n‚ùå No working models found. Please check:\")\n",
        "        print(\"1. Your Groq API key is valid\")\n",
        "        print(\"2. You have internet access\")\n",
        "        print(\"3. Check Groq documentation for current models\")\n",
        "\n",
        "# Simple chat interface for testing\n",
        "def quick_chat():\n",
        "    \"\"\"Quick chat interface for testing\"\"\"\n",
        "    agent = SimpleAgent(model=\"llama-3.1-8b-instant\")\n",
        "\n",
        "    print(\"\\nüí¨ Quick Chat Interface (type 'quit' to exit)\")\n",
        "    print(\"Available models:\", agent.get_available_models())\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"\\nYou: \")\n",
        "        if user_input.lower() in ['quit', 'exit', 'bye']:\n",
        "            break\n",
        "\n",
        "        response = agent.get_structured_response(user_input)\n",
        "        print(\"\\nAssistant:\")\n",
        "        print(json.dumps(response, indent=2))\n",
        "\n",
        "# Uncomment to run quick chat\n",
        "# quick_chat()"
      ]
    }
  ]
}